{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0: Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# set random seed\n",
    "np.random.seed = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Feature Extraction and Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我，会让这混乱，恢复秩序！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''some useful functions for feature extraction'''\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        if isinstance(file,str):\n",
    "        # If the file is a filename in string, Read in each one by one\n",
    "            image = mpimg.imread(file)\n",
    "        else:\n",
    "            image = file\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        else: feature_image = np.copy(image)      \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''find the best color space and hog channel for this task'''\n",
    "def getModel(params):\n",
    "    '''return the X_scaler and the Model'''\n",
    "    print(\"cspace:\",params[\"cspace\"])\n",
    "    print(\"hogchannel:\",params[\"hog_channel\"])\n",
    "    cspace=params[\"cspace\"]\n",
    "    hog_channel=params[\"hog_channel\"]\n",
    "    car_features = extract_features(cars, cspace=cspace, spatial_size=(32, 32),\n",
    "                            hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                            pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel)\n",
    "    notcar_features = extract_features(notcars, cspace=cspace, spatial_size=(32, 32),\n",
    "                            hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                            pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel)\n",
    "\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = 2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    # train classifier\n",
    "    # Use a linear SVC \n",
    "    svc = LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    %time svc.fit(X_train, y_train)\n",
    "    #print(t2-t, 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    print('Test AUC of SVC = ', roc_auc_score(y_test,svc.predict(X_test)))\n",
    "    print(\"-\"*10)\n",
    "    return X_scaler,svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''extract features and generates training and testing dataset for the first try'''\n",
    "\n",
    "# Divide up into cars and notcars\n",
    "cars=glob.glob(\"vehicles/*/*.png\")\n",
    "notcars=glob.glob(\"non-vehicles/*/*.png\")\n",
    "\n",
    "cspace=\"HLS\"\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 2 # Actually I don't think it is cool to define the vars used inside the function as parameter in global haha\n",
    "\n",
    "print(\"start feature extraction\")\n",
    "\n",
    "car_features = extract_features(cars, cspace=cspace, spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256), orient=orient, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel)\n",
    "\n",
    "print(\"finish feature extraction for cars\")\n",
    "\n",
    "notcar_features = extract_features(notcars, cspace=cspace, spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256), orient=orient, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel)\n",
    "\n",
    "print(\"finish feature extraction\")\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4932? maybe that's too much features, that's curse of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''first try: fit it with linear svc'''\n",
    "# train classifier\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Train Accuracy of SVC = ', svc.score(X_train, y_train))\n",
    "print('Test Accuracy of SVC = ', svc.score(X_test, y_test))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "prediction = svc.predict(X_test[0].reshape(1, -1))\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to predict with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''better evaluation metric: AUC'''\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test AUC of SVC = ', roc_auc_score(y_test,svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decision tree for feature reduction\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time dt.fit(X_train,y_train)\n",
    "print(\"test accuracy:\",dt.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of decision tree is worse than SVM.\n",
    "However, I use decision tree for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_features=[] #index of them\n",
    "for i,imp in enumerate(dt.feature_importances_):\n",
    "    if imp>0:\n",
    "        good_features.append(i)\n",
    "very_good_features=[]\n",
    "for i in good_features:\n",
    "    if dt.feature_importances_[i]>np.mean(dt.feature_importances_[good_features]):\n",
    "        very_good_features.append(i)\n",
    "len(very_good_features)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''try fit the svc with less features'''\n",
    "def model_with_features(features):\n",
    "    newsvc=LinearSVC()\n",
    "    %time newsvc.fit(X_train[:,features],y_train)\n",
    "    print('Test AUC of SVC = ', roc_auc_score(y_test,newsvc.predict(X_test[:,features])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_with_features(good_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_with_features(very_good_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the elimination of features improves the training speeds a lot but decreases the AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for csp in [\"HSV\",\"LUV\",\"HLS\",\"YUV\"]:\n",
    "    for hc in range(3):\n",
    "        try:\n",
    "            params[],params[]=grid_search(csp,hc)\n",
    "        except:\n",
    "            print(csp,hc,\"failed,next\")\n",
    "        dontoutput=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''try random forest'''\n",
    "\n",
    "# first get features done\n",
    "cspace=\"LUV\"\n",
    "hog_channel=0\n",
    "car_features = extract_features(cars, cspace=cspace, spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel)\n",
    "notcar_features = extract_features(notcars, cspace=cspace, spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256), orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=hog_channel)\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train classifier\n",
    "# Use random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(100)\n",
    "# Check the training time for the SVC\n",
    "%time rf.fit(X_train, y_train)\n",
    "#print(t2-t, 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test AUC of SVC = ', roc_auc_score(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''grid search on SVC and RF'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params_svc={\"C\":[1,10,100]}\n",
    "params_rf={\"n_estimators\":[50,100,250]}\n",
    "svc_gs=GridSearchCV(LinearSVC(),params_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_gs.best_params_,svc_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, even I forgot to put AUC as scoring metric, but it still shows that C=1 is the best parameter for SVC.\n",
    "The AUC was 0.983 for SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "auc=make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_gs=GridSearchCV(RandomForestClassifier(),params_rf,scoring=auc)\n",
    "%timeit rf_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_gs.best_params_,rf_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params[\"X_scaler\"],params[\"clf\"]=grid_search(\"HSV\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"slides\": 8,\n",
    "    \"basic\":48,\n",
    "    \"width\":100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params[\"cspace\"]=\"HSV\"\n",
    "params[\"hog_channel\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred(img,params):\n",
    "    '''pipeline for image predicting'''\n",
    "    img_features=extract_features([img], cspace=params[\"cspace\"], spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),hog_channel=params[\"hog_channel\"])\n",
    "    x = params[\"X_scaler\"].transform(img_features)\n",
    "    return params[\"clf\"].predict(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test the pred function\n",
    "test_img=plt.imread(\"vehicles/GTI_Far/image0000.png\")\n",
    "%time pred(test_img,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Sliding Windows and Detecting\n",
    "Awesome performance for the model trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roadimg=plt.imread(\"test_images/test1.jpg\")\n",
    "plt.imshow(roadimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, basic_size=32, x_overlap=0.5, num_ver_slides=8,width_basic=50):\n",
    "    \n",
    "    '''\n",
    "    This function is forked from the course and I made some change on it.\n",
    "    The changes I made are:\n",
    "    1. The span of image is the bottom half in default\n",
    "    2. The size of windows grow larger and larger when sliding further \n",
    "       from the center of the image\n",
    "    3. Work as a generator\n",
    "    \n",
    "    ''' \n",
    "    basic = int((img.shape[0]/2)/(num_ver_slides*basic_size))\n",
    "    for i in range(1,num_ver_slides):\n",
    "        # start and end position for this verticle slide\n",
    "        # update: from 1 because 0 would cause plenty of false positives\n",
    "        dist_from_centr = ((img.shape[0]/2)/num_ver_slides) * (i+1)\n",
    "        ey = int((img.shape[0]/2) + dist_from_centr)\n",
    "        win_size = basic*(i+1) # the windows size grows linearly when sliding out\n",
    "        sy = int(ey-win_size)\n",
    "        \n",
    "        # get the start and width of x\n",
    "        mid = img.shape[1]//2\n",
    "        width=width_basic*(i+1)\n",
    "        \n",
    "        if width>mid:\n",
    "            width=mid\n",
    "        \n",
    "        x_start=mid-width\n",
    "        \n",
    "        \n",
    "        # slide across x\n",
    "        nx_pix_per_step = int(win_size*(1-x_overlap)) \n",
    "        # OK, is that cool to use python.int, not np.int?\n",
    "        num_hori_slides = int(2*width/nx_pix_per_step) - 1\n",
    "        \n",
    "        for j in range(num_hori_slides):\n",
    "            sx = x_start+nx_pix_per_step * j\n",
    "            ex = sx + win_size\n",
    "            yield (sx,sy),(ex,ey)\n",
    "            # much less code, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rect(img, start, end, color=(0,0,255), thick=3):\n",
    "    '''little func for rect drawing'''\n",
    "    draw_on_image = np.copy(img)\n",
    "    cv2.rectangle(draw_on_image, start, end, color, thick)\n",
    "    return draw_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the sliding windows\n",
    "slider = slide_window(roadimg,basic_size=1,num_ver_slides=8,width_basic=150)\n",
    "drawon = np.copy(roadimg)\n",
    "for start,end in slider:\n",
    "    cv2.rectangle(drawon,start,end,(0,0,255),3)\n",
    "plt.imshow(drawon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vehicle_detect(img,params):\n",
    "    '''detect the vehicle, yield when detected'''\n",
    "    slider = slide_window(img,basic_size=params[\"basic\"],num_ver_slides=params[\"slides\"],width_basic=params[\"width\"])\n",
    "    for start,end in slider:\n",
    "        part = img[start[1]:end[1],start[0]:end[0],:]\n",
    "        part_resized = cv2.resize(part, (64,64))\n",
    "        \n",
    "        if pred(part_resized,params)==1:\n",
    "            yield start,end\n",
    "            # I love generator, much cooler than \"return\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params[\"slide\"]=8\n",
    "params[\"basic\"]=1\n",
    "params[\"width\"]=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "detector = vehicle_detect(roadimg,params=params)\n",
    "detected = np.copy(roadimg)\n",
    "for start,end in detector:\n",
    "    cv2.rectangle(detected, start,end, (0,0,255), 5)\n",
    "plt.imshow(detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no, plenty of false positives.\n",
    "\n",
    "It shows that AUC is not a good evaluation metric for this task.\n",
    "\n",
    "I need a better metric: which is just plot and show me the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''new way of gridsearch'''\n",
    "for cspace in [\"HSV\",\"LUV\",\"HLS\",\"YUV\"]:\n",
    "    for hc in range(3):\n",
    "        params[\"cspace\"]=cspace\n",
    "        params[\"hog_channel\"]=hc\n",
    "        try:\n",
    "            params[\"X_scaler\"],params[\"clf\"]=grid_search()\n",
    "        except:\n",
    "            print(\"failed\")\n",
    "            continue\n",
    "        detector = vehicle_detect(roadimg,params=params)\n",
    "        detected = np.copy(roadimg)\n",
    "        for start,end in detector:\n",
    "            cv2.rectangle(detected, start,end, (0,0,255), 5)\n",
    "        plt.imshow(detected)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congraduation, the hyperparameters picked this time are:\n",
    "- cspace: HSV\n",
    "- hog_channel: 2\n",
    "- clf: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params[\"cspace\"]=\"HSV\"\n",
    "params[\"hog_channel\"]=2\n",
    "params[\"X_scaler\"],params[\"clf\"]=grid_search(params[\"cspace\"],params[\"hog_channel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img in glob.glob(\"test_images/*.jpg\"):\n",
    "    roadimg=plt.imread(img)\n",
    "    detector = vehicle_detect(roadimg,params=params)\n",
    "    detected = np.copy(roadimg)\n",
    "    for start,end in detector:\n",
    "        cv2.rectangle(detected, start,end, (0,0,255), 5)\n",
    "    plt.imshow(detected)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Eliminating False Positives and Duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# heatmap for duplication reduction\n",
    "class LastNFrames(object):\n",
    "    def __init__(self,n):\n",
    "        self.queue=[]\n",
    "        self.n=n\n",
    "    def join(self,item):\n",
    "        '''join the queue, and pop the first item if the queue is full'''\n",
    "        self.queue.append(item)\n",
    "        if len(self.queue)>self.n:\n",
    "            self.queue.pop()\n",
    "    def init_with_default(self,default):\n",
    "        '''init the queue which fulfilled with default term'''\n",
    "        self.queue=[default for i in range(self.n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heatmap_valid(predictions,imgshape,lnf,params):\n",
    "    '''valid the prediction in heatmap, to eliminate the false positives'''\n",
    "    \n",
    "    # join the pred\n",
    "    lnf.join(predictions)\n",
    "    \n",
    "    # creates a heatmap\n",
    "    heatmap=np.zeros(imgshape)\n",
    "    for frames in lnf.queue:\n",
    "        for start,end in frames:\n",
    "            heatmap[start[1]:end[1],start[0]:end[0]]+=1\n",
    "            \n",
    "    # validation and yield\n",
    "    ## FutureImprove: change the \"predictions\" to \"all predictions in frames\"\n",
    "    \n",
    "    for start,end in predictions:\n",
    "        part=heatmap[start[1]:end[1],start[0]:end[0]].reshape(-1)\n",
    "        if part.mean()>=params[\"thre_lnf\"]:\n",
    "            yield start,end\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seperated(rect1,rect2):\n",
    "    '''if not overlap, return True'''\n",
    "    return rect1[1][0]<rect2[0][0] or rect1[0][0]>rect2[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rect_combine(rect1,rect2):\n",
    "    rects=np.vstack([np.array(rect1),np.array(rect2)])\n",
    "    return (rects[:,0].min(),rects[:,1].min()),(rects[:,0].max(),rects[:,1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def duplication_eliminate(predictions,plot=False):\n",
    "    '''recursively reduce all duplications'''\n",
    "    if plot==True:\n",
    "        todraw=np.copy(roadimg)\n",
    "        for start,end in predictions:\n",
    "            cv2.rectangle(todraw,start,end,(0,0,255),3)\n",
    "        plt.imshow(todraw)\n",
    "        plt.show()\n",
    "    if len(predictions)<2:\n",
    "        return predictions\n",
    "    temp = predictions[0]\n",
    "    t_iter=0\n",
    "    max_iter=100\n",
    "    while t_iter<max_iter:\n",
    "        found = False\n",
    "        for i in range(1,len(predictions)):\n",
    "            if not seperated(predictions[i],temp):\n",
    "                found = True\n",
    "                temp = rect_combine(temp,predictions[i])\n",
    "                predictions.remove(predictions[i])\n",
    "                break\n",
    "        t_iter+=1\n",
    "        if not found:\n",
    "            return [temp]+duplication_eliminate(predictions[1:])      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the duplication elimination\n",
    "preds=[(start,end) for start,end in vehicle_detect(roadimg,params)]\n",
    "todraw=np.copy(roadimg)\n",
    "todraw2=np.copy(roadimg)\n",
    "for start,end in preds:\n",
    "    cv2.rectangle(todraw,start,end,(0,0,255),3)\n",
    "plt.imshow(todraw)\n",
    "plt.show()\n",
    "for start,end in duplication_eliminate(preds,True):\n",
    "    cv2.rectangle(todraw2,start,end,(0,0,255),3)\n",
    "plt.imshow(todraw2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Test On Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "def process_image(img):\n",
    "    global lnf\n",
    "    detector=vehicle_detect(img,params)\n",
    "    predictions_raw=[(start,end) for start,end in detector]\n",
    "    for start,end in predictions_raw:\n",
    "        cv2.rectangle(img,start,end,(150,150,150),3) # draw red rects\n",
    "    predictions=[(start,end) for start,end in heatmap_valid(predictions_raw,img.shape[:2],lnf,params)]\n",
    "    for start,end in duplication_eliminate(predictions):\n",
    "        cv2.rectangle(img,start,end,(0,0,255),5) # draw blue rects\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trial init\n",
    "trial_i=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params tuning\n",
    "params[\"basic\"]=1\n",
    "params[\"slides\"]=8\n",
    "params[\"width\"]=250\n",
    "\n",
    "params[\"n_lnf\"]=15\n",
    "params[\"thre_lnf\"]=1.5 * params[\"slides\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# video generation\n",
    "lnf=LastNFrames(params[\"n_lnf\"])\n",
    "video_output = 'trial %d %s.mp4'%(trial_i,\"a\")\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(40,50)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)\n",
    "trial_i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3]",
   "language": "python",
   "name": "Python [py3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
